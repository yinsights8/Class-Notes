{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1d765c38",
   "metadata": {},
   "source": [
    "# Mostly used libraries in NLP\n",
    "\n",
    "- 1. nltk (natural language toolkit)\n",
    "- 2. gensim\n",
    "- 3. spacy\n",
    "\n",
    "nltk.download(\"package_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437499e4",
   "metadata": {},
   "source": [
    "## Feature Engineering "
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4b9b64a",
   "metadata": {},
   "source": [
    "In this process we convert the Text data to  numeric / vector format, there are two methods to convert text to intiger.\n",
    "- 1. frequency based \n",
    "- 2. prediction based"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34203d7b",
   "metadata": {},
   "source": [
    "-1. Frequency based  (word frequency)\n",
    "    - 1. Countvectorizer\n",
    "    \t- first it will create a list of unique words from the documents, and will create a                   dataframe where it contain the count of each unique word in a document (record)\n",
    "    - 2. TFIDFVectorizer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88390aa4",
   "metadata": {},
   "source": [
    "- 2. Prediction based (Algorithm)\n",
    "\t- 1. word2vec\n",
    "    - 2. fast - text\n",
    "    - 3. Doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de33482e",
   "metadata": {},
   "source": [
    "##  Modeling "
   ]
  },
  {
   "cell_type": "raw",
   "id": "8928de3c",
   "metadata": {},
   "source": [
    "algorithms :-\n",
    "    1. Support vector machine (SVM)\n",
    "    2. Logistic Regression\n",
    "    3. Decission Tree classifier\n",
    "    4. Adaboost classifier\n",
    "    5. naive bayes\n",
    "    6. ANN classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93f7f3b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fcf60b7d",
   "metadata": {},
   "source": [
    "- 1. classification report \n",
    "- 2. Accuracy score\n",
    "- 3. Confussion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d816876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08105c8f",
   "metadata": {},
   "source": [
    "## NLP Preprocessing Steps"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3562f58",
   "metadata": {},
   "source": [
    "1. removing spaces\n",
    "2. contraction mapping\n",
    "3. Handling accented characters\n",
    "4. cleanning (stopwords except negative words)\n",
    "\tcleanning\n",
    "5. lemmatization\n",
    "\n",
    "6. train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0eb581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

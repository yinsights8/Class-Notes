{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "048ee8e8",
   "metadata": {},
   "source": [
    "### 1. Ngrams"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0469f96",
   "metadata": {},
   "source": [
    "Ngrams are use to get the insights from the data or to uderstand the words like -ve and +ve words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc1353c",
   "metadata": {},
   "source": [
    "### WordCloud"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45606b00",
   "metadata": {},
   "source": [
    "wordcloud is use to extract the Domain specific words from the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74125966",
   "metadata": {},
   "source": [
    "### 2. keyphrase Extraction"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebdffefd",
   "metadata": {},
   "source": [
    "- we use keyphrase extraction to extract the important phrases from the text\n",
    "- extracting the important keywords from the text\n",
    "\n",
    "we use RAKE and YAKE libraries for keyphrase extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789969ef",
   "metadata": {},
   "source": [
    "## Vectorizers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69bb48a2",
   "metadata": {},
   "source": [
    "frequency based word embading techniques\n",
    "- 1. Count Vectorizer :- count of the words \n",
    "\n",
    "- 2. tfidf vectorizer :\n",
    "\tTF  : Term Frequency\n",
    "    DF  : Document Frequency\n",
    "    IDf : Inverse Document Frequency\n",
    "    \n",
    "    TF = frequency of term 't' in a document / total number of words in that document\n",
    "    \n",
    "    DF = No. of documents containing term 't' / total number of documents\n",
    "    IDF = log (1/DF)\n",
    "    \n",
    "    TF-IDF = TF * IDF\n",
    "\n",
    "in tfidf frequency of word increases, weightege of words decreases"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6e091ac2",
   "metadata": {},
   "source": [
    "Drawbaks of count vectorizer and tfidf vectorizer\n",
    "\t- 1. curse of dimentionality\n",
    "    - 2. order is not maintained\n",
    "    - 3. it is not considering actual meaninig of word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa92c9e",
   "metadata": {},
   "source": [
    "### Word2vect \n",
    "https://www.analyticsvidhya.com/blog/2021/06/part-6-step-by-step-guide-to-master-nlp-word2vec/"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f3acd33",
   "metadata": {},
   "source": [
    "word2vect uses simple neural network, which has one hidden layer.\n",
    "Word2vec is a technique for natural language processing (NLP) published in 2013. The word2vec algorithm uses a neural network model to learn word associations from a large corpus of text. Once trained, such a model can detect synonymous words or suggest additional words for a partial sentence."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1597ba4",
   "metadata": {},
   "source": [
    "we can use word2vect in two ways\n",
    "- 1. pretrain model\n",
    "- 2. costume model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94e1ed29",
   "metadata": {},
   "source": [
    "Architechture of word2vec\n",
    "- 1. CBOW (contineous bag of words)\n",
    "\t- multiple inputs will pass to hidden layer and will produce sigle output\n",
    "    \n",
    "- 3. skipgram\n",
    "   - single input will pass to hidden layer and will produce multiple output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9cfc93f4",
   "metadata": {},
   "source": [
    "- Assumption of word2vec\n",
    "word with the similar context will have similar vector representation\n",
    "\t vector = magnitude and direction\n",
    "it uses cosine similarity or cosine distance to find the similar context in a words.\n",
    "\n",
    "Cosine distance/similarity = A.B / |A| * |B|\n",
    "\n",
    "value close to -1 :- vectors are not similar \n",
    "value close to +1 :- vectors are similar\n",
    "\n",
    "For example,  \n",
    "cos(0) = 1            θ ⇓ cosθ ⇧\n",
    "cos(180) = -1         θ ⇧ cosθ ⇓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0506231b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6da42dd7",
   "metadata": {},
   "source": [
    "### 1. Information Extraction\n",
    "https://www.analyticsvidhya.com/blog/2020/06/nlp-project-information-extraction/"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a616d3e9",
   "metadata": {},
   "source": [
    "Information Extraction :-\n",
    "    The Task of information extraction is to get the meaningfull insights or information from the       unstructured text data and presenting it in a structured format.\n",
    "    \n",
    "    Using information extraction, we can retrieve pre-defined information such as the name of a         person, location of an organization, or identify a relation between entities, and save this         information in a structured format such as a database.\n",
    "\n",
    "\tfor example, if we pass the resumes to the model, our model will extract only meaniningfull data     such as Name, Location, Skills, Qualifications, etc."
   ]
  },
  {
   "cell_type": "raw",
   "id": "31504c28",
   "metadata": {},
   "source": [
    "Sublock of the information extraction\n",
    "\t- 1. KeyPhrase Extraction\n",
    "    - 2. Named Entity Extraction / Recognition\n",
    "    - 3. Relation Extraction\n",
    "    \n",
    "NOTE :- SpaCy library will help us to extract the information from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f60188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e08ccbe8",
   "metadata": {},
   "source": [
    "### 2. Name Entity Extraction\n",
    "- https://www.analyticsvidhya.com/blog/2021/06/part-10-step-by-step-guide-to-master-nlp-named-entity-recognition/"
   ]
  },
  {
   "cell_type": "raw",
   "id": "889bda24",
   "metadata": {},
   "source": [
    "1. Named Entity Extraction or Recognition\n",
    "\tNamed entity extraction or recognition is one of the key entity detection method\n",
    "    \n",
    "    In simple words, Named Entity Recognition is the process of detecting the named entities such as     person names, location names, company names, etc from the text\n",
    "    \n",
    "    With the help of named entity recognition, we can extract key information to understand the         text, or merely use it to extract important information to store in a database."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e38db5b0",
   "metadata": {},
   "source": [
    "Aplications\n",
    "- 1. Automated Chatbot \n",
    "- 2. Content Analyser\n",
    "- 3. Consumer insights ETC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fcde5c",
   "metadata": {},
   "source": [
    "### 3. Relation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84424a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1192c2c",
   "metadata": {},
   "source": [
    "### 4. KeyPhrase Extraction "
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ef54464",
   "metadata": {},
   "source": [
    "Extracting Important phrases from the data\n",
    "\n",
    "Ways to do keyphrase extraction\n",
    "- 1. Ngrams \n",
    "- 2. Unsupervised machine learning algorithms\n",
    "\t- 1. RAKE (Rapid Automatic Keyword Extraction)\n",
    "    - 2. YAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601c33bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "6af7b0f2",
   "metadata": {},
   "source": [
    "flow chart of unsupervised algorithm for keypharase extraction.\n",
    "\n",
    "Raw Text >> Candidate generation >> Candidate Scoring >> Post Processing and Final Ranking\n",
    "\n",
    "1. Candidate Generation (Extracting all the phrases)\n",
    "2. Candidate Scoring    (give score to phrases) >> (important features)\n",
    "3. Post processing      (laveshtein distance)\n",
    "\t\t\t\t\t\t(i.e no. of operation taken by converting a word to another)\n",
    "                        (ex, 'game' >> 'games' ---> 1 operation)\n",
    "                        (ex, 'RAN' >> 'SUN' ---> 4 operation)\n",
    "                             delete 'R' \n",
    "                             substitude 'S' \n",
    "                             delete 'A'\n",
    "                             sunstitude 'U'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f76dabf",
   "metadata": {},
   "source": [
    "### Lavenshtein Distance\n",
    "https://medium.com/analytics-vidhya/levenshtein-distance-for-dummies-dd9eb83d3e09"
   ]
  },
  {
   "cell_type": "raw",
   "id": "78c3f91c",
   "metadata": {},
   "source": [
    "Levenshtein distance is a string metric for measuring the difference between two sequences. Informally, the Levenshtein distance between two words is the minimum number of single-character edits (insertions, deletions or substitutions) required to change one word into the other\n",
    "\n",
    "- Lower the lavesnshtein distance higher the similarity between the words\n",
    "- Higher the lavesnshtein distance lower the similarity between the words\n",
    "\n",
    "The Purpose of the lavenshtein distance is that, it reduces the KeyPhrase Count and increases the importance phrases. \n",
    "for example :-\n",
    "\t1. nice movie\n",
    "    2. nicely movie\n",
    "both the words are similar so it will only consider on keyphrase randomly and another one will be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225793a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7bb4e66",
   "metadata": {},
   "source": [
    "### RAKE (Rapid Automatic Key Phrase Extraction)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "93231ebf",
   "metadata": {},
   "source": [
    "data = SAARC is consist of south asian countries, india is supporting SAARC\n",
    "\n",
    "1. Candidate Generation\n",
    "   it will split the text or data from stopwords and punctuations.\n",
    "   \n",
    "   result = [SAARC, consist, south asian countries, india,  supporting SAARC]\n",
    "   \n",
    "2. Candidate Scoring\n",
    "\tscore = DEGREE / FREQUENCY of unique words in candidate generation\n",
    "    \n",
    "3. Scoring = \n",
    "\tGreater the KeyPhrase score higher the keyPhrase importance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d96b65",
   "metadata": {},
   "source": [
    "### YAKE (Yet Another KeyPhrase Extraction)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2fbba59",
   "metadata": {},
   "source": [
    "data = SAARC is consist of south asian countries, india is supporting SAARC\n",
    "\n",
    "1. Candidate Generation\n",
    "\tit will split the text or data if word is between the stopwords or the word between the stopword     and punctuation.\n",
    "    Ex. is consist of and ,india is\n",
    "    \t- SAARC, south asian countries supporting SAARC\n",
    "        \n",
    "2. Candidate Scoring \n",
    "\tit calculates the five score for every word (a,b,c,d,e)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5317bec6",
   "metadata": {},
   "source": [
    "casing (a) = MAX (count(w is capital), count of (w is acronym))  / 1 + log( count(w) )\n",
    "\n",
    "word position (b) = log (log (3 + median (sen(w))))\n",
    "     where sen(w) = list of position of word in document\n",
    "     \n",
    "word frequency score (c) = count of word / mean of (count) + std.(count)\n",
    "\n",
    "word relatedness = 1 + (WR + WL) * count(w) / max count +PL +PR\n",
    "\twhere, WR = no. of unique words on right / total number of words on right \n",
    "    \n",
    "    \t   WL = No. of unique words on left / total number of words on left\n",
    "           \n",
    "           PL = total words on left / max count\n",
    "           PR = total words on right / max count \n",
    "           \n",
    "           \t\tmax count = total words on the documents\n",
    "                \n",
    "word different score = No. of sentences coutaining that term / total no. of sentences\n",
    "\n",
    "Final Score  \n",
    "score (w) d * b / a + (c/d) + (e/d)\n",
    "\n",
    "where, a = casing\n",
    "\t   b = word position score\n",
    "       c = frequency score\n",
    "       d = word relatedness \n",
    "       e = word different score\n",
    "       \n",
    "##### NOTE :- Capitle is considerd as title case words"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b4a3d43",
   "metadata": {},
   "source": [
    "Keyphrase score = Product (score (A), score (B)) / 1 + (Sum of score of A,B) * count(keyphrase)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3fb8416",
   "metadata": {},
   "source": [
    "lower the KeyPhrase score , higher the keyphrase significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f327556d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae903c42",
   "metadata": {},
   "source": [
    "- https://towardsdatascience.com/k-means-clustering-explain-it-to-me-like-im-10-e0badf10734a\n",
    "- https://www.analyticsvidhya.com/blog/2021/01/in-depth-intuition-of-k-means-clustering-algorithm-in-machine-learning/#:~:text=For%20each%20value%20of%20K,value%20will%20start%20to%20decrease."
   ]
  },
  {
   "cell_type": "raw",
   "id": "80e59c8e",
   "metadata": {},
   "source": [
    "- For K-means Clusturing algorithm the datapoints will be linearly separable and unlabled (No         target)\n",
    "- K-Means Clusturing is a unsuperviesed machine learning algorithm, which is use to create a           clusture of different classes of unlabled datasets.\n",
    "\n",
    "- It is a distance based Algorithm\n",
    "\n",
    "- in order to create a k-number of cluster, user needs to provide a k value to the model.\n",
    "\n",
    "- User can find the K-value by Elbow method.\n",
    "\n",
    "- On the basis of that K values, random k-datapoints from the existing dataset will be considerd as   a centroids or center of clusture that we are going to make, or user can also provide random k or   centroids values to the model.\n",
    "\n",
    "- then we calculate the distance of each centroid from each data points. once the distances are       calcuated, we assign the cluster to the centroid on the basis of close distance of centroid to       datapoints. (Distances are claculated by Ecludien Distance) we repeate this process until each       cluster get assigned to each centroid.\n",
    "\n",
    "- New points for centroid will get updated, by sum of group of one cluster devided by count of         elements in a cluster. (Mean of clusters data points)\n",
    "    Ex :- 3 blue points belongs to X and 3 yellow points belongs to Y\n",
    "            new_centroid_x  = (x1 + X2 + x3) / 3\n",
    "            new_centroid_y  = (y1 + y2 + y3) / 3\n",
    "    where x1, x2, and x3 are the x-coordinates of each of the 3 points of the blue cluster. And y1,     y2, and y3 are the y-coordinates of each of the 3 points of the blue cluster. \n",
    "  NOTE :- Each Attribute will have its own Centroid, Number of attributes == number of centroids.\n",
    "  \n",
    "- further on the basis of new centroid again distances will be calculated and once again our           centroids will shift towords the assigned cluster.\n",
    "\n",
    "- all the methods will be repeated again and again, until there will not much or no change in in the last distance and the new disatace of the centroids from the datapoints. (lastly centroid will get placed at the center of the cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53335820",
   "metadata": {},
   "source": [
    "## Steps involve in K-Meas Clusters"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8765ac80",
   "metadata": {},
   "source": [
    "- Step 1 :- Find the best K-values for the Model by \"WCSS inertia\" (Within cluster sum of squared               (Elbow Method))\n",
    "- Step 2 :- select K - Points randomly (Centroid)\n",
    "- Step 3 :- Calculate the distance from each centroid to each data points.\n",
    "- Step 4 :- Make a cluster (after calculated distance to each centroid will be assign a cluster)\n",
    "            in this step Centroid will shifts its position toword the cluster. (Close distance will             be consider to make a cluster)\n",
    "- Step 5 :- Compute new Centroid for each Cluster \n",
    "           new_centroid = Sum of datapoints in each cluster / total number of points in each cluster\n",
    "\n",
    "- Step 6 :-  Assess the Quality of Each Cluster (WCSS :- Within-Cluster Sum of Squares)\n",
    "             Since k-means can’t see the clustering as we can, it measures the quality by finding                the variation within all the clusters. The basic idea behind k-means clustering is                  defining clusters so that the within-cluster variation is minimized. We calculate                    something called Within-Cluster Sum of Squares (WCSS) to quantify this variance:\n",
    "             \n",
    "- Step 7 :-   Repeat Steps 3–6\n",
    "\n",
    "From the last two iterations, we will be seeing that the clusters haven’t changed. This means that the algorithm has converged and we stop the clustering process. We then choose the clusters with the least WCSS. This also happens to be those of the last two iterations. So, they are going to be our final clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62325975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfac4272",
   "metadata": {},
   "source": [
    "Code - and Explanation\n",
    "https://www.tutorialspoint.com/machine_learning_with_python/clustering_algorithms_k_means_algorithm.htm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c172ba7c",
   "metadata": {},
   "source": [
    "Step 1 − First, we need to specify the number of clusters, K, need to be generated by this                    algorithm.\n",
    "\n",
    "Step 2 − Next, randomly select K data points and assign each data point to a cluster. In simple              words, classify the data based on the number of data points.\n",
    "\n",
    "Step 3 − Now it will compute the cluster centroids.\n",
    "\n",
    "Step 4 − Next, keep iterating the following until we find optimal centroid which is the assignment            of data points to the clusters that are not changing any more −\n",
    "\n",
    "    4.1 − First, the sum of squared distance between data points and centroids would be computed.\n",
    "\n",
    "    4.2 − Now, we have to assign each data point to the cluster that is closer than other cluster             (centroid).\n",
    "\n",
    "    4.3 − At last compute the centroids for the clusters by taking the average of all data points of           that cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b492fd65",
   "metadata": {},
   "source": [
    "- Influence of Ouliers in k-Means Clustering\n",
    "https://medium.com/analytics-vidhya/effect-of-outliers-on-k-means-algorithm-using-python-7ba85821ea23#:~:text=We%20observe%20that%20the%20outlier,algorithm%20is%20influenced%20by%20outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52587dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8b97731",
   "metadata": {},
   "source": [
    "# Ensemble Technique"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0aa6bbf1",
   "metadata": {},
   "source": [
    "Ensembles >> Ensemble is the method in which we can combine the multiple trees together.\n",
    "\n",
    "1. Bagging >> Boostrap (B) + Aggregation/Aggregating (Agg)  >> Parallel Approach\n",
    "2. Boosting >> Sequential Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564b98f0",
   "metadata": {},
   "source": [
    "# Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "769721fb",
   "metadata": {},
   "source": [
    "Random Forest >> Multiple Trees >> Forest\n",
    "              >>  Random selection of raw records\n",
    "              >> Raw Sampling"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5aa1c6f7",
   "metadata": {},
   "source": [
    "1. Random forest is a Supervised Machine Learning Algorithm\n",
    "2. It is useful for classification as well as Regression\n",
    "3. We do follow the Bootstrap Aggregation in Random Forest\n",
    "4. Random FOrest will follow the Parallel Approach and it will train the Multiple DT\n",
    "5. For regression concerns, While doing the Aggregation. In the Backend average will get calculated\n",
    "for the final predicted values.\n",
    "6. Likewise, FOr solving the Classification concerns. At the time of Aggregation we do follow the\n",
    "Votting criteria. In which we can refer Hard Votting. (Maximum count)\n",
    "7. After Aggreation for Regression as well as Classification. Final Master model will get created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06400852",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c905f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "Types of Voting Criteria:\n",
    "    \n",
    "    1. Soft Voting >> Prob\n",
    "    2. Hard Voting  >> Max Count\n",
    "    \n",
    "     Class0  Class1\n",
    "M1 >> [0.4,  0.9]  >> Class1\n",
    "M2 >> [0.9,  0.8]  >> Class0\n",
    "M3 >> [0.5,  0.3]  >> Class0\n",
    "\n",
    "If we are performing Hard Voting here. Then what will be our predicted class?\n",
    ">>> Class 0  >> Because Maximun count which we are getting it from Class 0\n",
    "\n",
    "Hard Voting  >> Predicted Class >> Class 0\n",
    "\n",
    "\n",
    "     Class0  Class1\n",
    "M1 >> [0.44,  0.97]  >> Class1\n",
    "M2 >> [0.98,  0.99]  >> Class1\n",
    "M3 >> [0.54,  0.39]  >> Class0\n",
    "\n",
    "Soft Voting >> Predicted Class >> Class1\n",
    "\n",
    "\n",
    "M1 >> [0.55,  0.87]  >> Class1\n",
    "M2 >> [0.95,  0.89]  >> Class0\n",
    "M3 >> [0.58,  0.39]  >> Class0\n",
    "\n",
    "Soft Voting >> Predicted Class >> CLass 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db0b94e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6933333333333334"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.55 + 0.95 + 0.58)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "422a8d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7166666666666667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.87 + 0.89 + 0.39)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e69f64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6533333333333333"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.44 + 0.98 + 0.54)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "204189ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7833333333333333"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.97 + 0.99 + 0.39)/3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c7313d",
   "metadata": {},
   "source": [
    "# Random Forest Advantages"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89adcaa9",
   "metadata": {},
   "source": [
    "1. It is useful for classification as well as Regression\n",
    "2. It is not senstive to Outliers \n",
    "3. No need to perform Scaling / Scaling is not Requied\n",
    "4. It reduces the Overfitting of Decision Tree or Problem. And due to which we can get good Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3d4bff",
   "metadata": {},
   "source": [
    "# Random Forest Disadvantages"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8b9049b",
   "metadata": {},
   "source": [
    "1. It requied High Computational Power (Because we are training Multiple Trees)\n",
    "2. Complexity will be high"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

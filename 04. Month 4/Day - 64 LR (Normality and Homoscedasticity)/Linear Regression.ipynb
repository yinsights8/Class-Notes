{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96f6252d",
   "metadata": {},
   "source": [
    "# Best Fit Line"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35d61bbb",
   "metadata": {},
   "source": [
    "1. The line which passes through the maximum number of data points. It is called as Best Fit Line\n",
    "2. Line on which we are having lowest mean squared error (MSE) or Sum of Squared error (SSE)\n",
    "3. Gradient Descent algorithm will help to find the best fit line\n",
    "4. G.D algorithm finds single line (Best Fit Line) from infinite number of possibilities \n",
    "or regression lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46c204f",
   "metadata": {},
   "source": [
    "# Gradient Descent Algorithm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d80ccbf7",
   "metadata": {},
   "source": [
    "1. Gradient Descent algorithm will work on the PD.\n",
    "2. It will help to reduce the Cost Function or Loss Function\n",
    "3. It will help to get the best M and C Value\n",
    "4. We do follow the baby steps while working on the GD algorithm\n",
    "5. Baby steps are totally depends on the learning rates that we do keep in the model.\n",
    "6. Default or Best learning rate value will be 0.001 (L = 0.001)\n",
    "7. If we will change the learning rate as L = 1, Then we might overshoot the Global Minima."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e48d6fb",
   "metadata": {},
   "source": [
    "# Mean Squared Error"
   ]
  },
  {
   "cell_type": "raw",
   "id": "678c31ac",
   "metadata": {},
   "source": [
    "Mean Squared Error (MSE) = sum(Ya - Yp)^2/N\n",
    "N = Number of samples\n",
    "\n",
    "In Linear regression, The cost function as also called as Loss Function.\n",
    "\n",
    "MSE = Cost Function = Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5569e6",
   "metadata": {},
   "source": [
    "# Residuals"
   ]
  },
  {
   "cell_type": "raw",
   "id": "785fd02f",
   "metadata": {},
   "source": [
    "Error or Diff between Actual values and Predicted Values or Data Points\n",
    "\n",
    "Residuals >> (Yactual - Ypredicted)\n",
    "\n",
    "1. Positive  >> If data points are above the regression line.\n",
    "2. Negative  >> If Data points are below the regression line.\n",
    "3. Zero      >> If the Data Points are on the regression Line are 0th pposition line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15a1ecb",
   "metadata": {},
   "source": [
    "# Normality or Residuals"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ef2b554",
   "metadata": {},
   "source": [
    "Normality   >> Normality is the Normal Distribuation of the errors or the data points\n",
    "\n",
    "1. We always try to keep our data points near to the Mean\n",
    "2. Or else, We always try to gather the data points in first,second and third Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465bed6d",
   "metadata": {},
   "source": [
    "# Homoscedasticity"
   ]
  },
  {
   "cell_type": "raw",
   "id": "22e9d8e0",
   "metadata": {},
   "source": [
    "1. Homoscedasticity in which the residuals or the errors will be on the constant rate from the linear line\n",
    "2. If we do get the variations in the residuals or the data points from the regression line. Then that will be Heteroscedasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06144bb4",
   "metadata": {},
   "source": [
    "# Standard Deviation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "313c89cc",
   "metadata": {},
   "source": [
    "1. Standard Deviation will help us to identify the spread of the Data Points.\n",
    "\n",
    "2. Low Standard Deviation  >> LSD in which most of the data points wiill be closed to the mean value\n",
    "                              (This is the Expected Case)\n",
    "    \n",
    "3. High STD  >> Values / Data Points are far away from the Mean Value (We always try to reduce the impact of data points or errors or Residuals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
